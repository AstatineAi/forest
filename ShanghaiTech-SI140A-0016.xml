<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="default.xsl"?>
<fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>385</fr:anchor><fr:addr
type="user">ShanghaiTech-SI140A-0016</fr:addr><fr:route>ShanghaiTech-SI140A-0016.xml</fr:route><fr:title
text="Estimation (Basic Problem)">Estimation (Basic Problem)</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>10</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>Given a random variable <fr:tex
display="inline"><![CDATA[X]]></fr:tex> and a sample <fr:tex
display="inline"><![CDATA[ X_1, X_2, \dots , X_n]]></fr:tex> we want to estimate the distribution of <fr:tex
display="inline"><![CDATA[X]]></fr:tex>.</fr:p><fr:p>The <fr:strong>Estimator</fr:strong> is a function <fr:tex
display="inline"><![CDATA[\hat {X} = g(X_1, X_2, \dots , X_n)]]></fr:tex>. The <fr:strong>cost function</fr:strong> is a function <fr:tex
display="inline"><![CDATA[c(X, \hat {X})]]></fr:tex> that measures the quality of the estimator. We want to minimize the expected cost <fr:tex
display="inline"><![CDATA[E(c(X, \hat {X}))]]></fr:tex>.</fr:p><fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>344</fr:anchor><fr:addr
type="user">ShanghaiTech-SI140A-0017</fr:addr><fr:route>ShanghaiTech-SI140A-0017.xml</fr:route><fr:title
text="Least Square Estimation">Least Square Estimation</fr:title><fr:taxon>Definition</fr:taxon><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>10</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>Given a random variable <fr:tex
display="inline"><![CDATA[X]]></fr:tex> and a sample <fr:tex
display="inline"><![CDATA[ X_1, X_2, \dots , X_n]]></fr:tex>, let the cost function be the square of the difference between <fr:tex
display="inline"><![CDATA[X]]></fr:tex> and <fr:tex
display="inline"><![CDATA[\hat {X}]]></fr:tex>:

  <fr:tex
display="block"><![CDATA[     c(X, \hat {X}) = |X - \hat {X}|^2   ]]></fr:tex>

  The best guess is called the <fr:strong>Least Square Estimator</fr:strong>:</fr:p></fr:mainmatter><fr:backmatter /></fr:tree><fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>345</fr:anchor><fr:addr
type="user">ShanghaiTech-SI140A-0018</fr:addr><fr:route>ShanghaiTech-SI140A-0018.xml</fr:route><fr:title
text="Linear Least Square Estimation">Linear Least Square Estimation</fr:title><fr:taxon>Definition</fr:taxon><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>10</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>If the estimator in a LSE estimation is <fr:strong>linear</fr:strong>, then it is called a <fr:strong>Linear Least Square Estimator (LLSE)</fr:strong>.</fr:p><fr:p>The LLSE of <fr:tex
display="inline"><![CDATA[Y]]></fr:tex> given <fr:tex
display="inline"><![CDATA[X]]></fr:tex>, denoted by <fr:tex
display="inline"><![CDATA[L [Y \mid  X] ]]></fr:tex> is the linear function <fr:tex
display="inline"><![CDATA[a + b X]]></fr:tex> that minimizes the mean square error <fr:tex
display="inline"><![CDATA[E[(Y - a - b X)^2]]]></fr:tex>.

  <fr:tex
display="block"><![CDATA[     L [Y \mid  X] = E[Y] + \frac {\operatorname {Cov}(X, Y)}{\operatorname {Var}(X)} (X - E[X])   ]]></fr:tex></fr:p></fr:mainmatter><fr:backmatter /></fr:tree><fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>346</fr:anchor><fr:addr
type="user">ShanghaiTech-SI140A-0019</fr:addr><fr:route>ShanghaiTech-SI140A-0019.xml</fr:route><fr:title
text="Minimum Mean Square Estimation">Minimum Mean Square Estimation</fr:title><fr:taxon>Definition</fr:taxon><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>10</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>If the estimator is an arbitrary function, and the cost function is the mean square error, then the estimator is called a <fr:strong>Minimum Mean Square Estimator (MMSE)</fr:strong>.</fr:p><fr:p>The MMSE of <fr:tex
display="inline"><![CDATA[Y]]></fr:tex> given <fr:tex
display="inline"><![CDATA[X]]></fr:tex> is given by the conditional expectation:

  <fr:tex
display="block"><![CDATA[     E[Y \mid  X]   ]]></fr:tex></fr:p></fr:mainmatter><fr:backmatter /></fr:tree></fr:mainmatter><fr:backmatter><fr:tree
toc="false"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:title
text="Context">Context</fr:title><fr:authors /></fr:frontmatter><fr:mainmatter><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="false"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>386</fr:anchor><fr:addr
type="user">ShanghaiTech-SI140A-0010</fr:addr><fr:route>ShanghaiTech-SI140A-0010.xml</fr:route><fr:title
text="Courses › Probability &amp; Statistics for EECS Fall 2024 › Lectures › No. 8: Conditional Expectation"><fr:link
type="local"
href="ShanghaiTech-SI140A-Lectures.xml"
addr="ShanghaiTech-SI140A-Lectures"
title="Courses › Probability &amp; Statistics for EECS Fall 2024 › Lectures"><fr:link
type="local"
href="ShanghaiTech-SI140A-index.xml"
addr="ShanghaiTech-SI140A-index"
title="Courses › Probability &amp; Statistics for EECS Fall 2024"><fr:link
type="local"
href="ShanghaiTech-Courses.xml"
addr="ShanghaiTech-Courses"
title="Courses">Courses</fr:link> › Probability &amp; Statistics for EECS Fall 2024</fr:link> › Lectures</fr:link> › No. 8: Conditional Expectation</fr:title><fr:taxon>Lecture</fr:taxon><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>10</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>338</fr:anchor><fr:addr
type="user">ShanghaiTech-SI140A-0011</fr:addr><fr:route>ShanghaiTech-SI140A-0011.xml</fr:route><fr:title
text="Law of Total Expectation">Law of Total Expectation</fr:title><fr:taxon>Theorem</fr:taxon><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>10</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>Let <fr:tex
display="inline"><![CDATA[X_1, X_2, \dots , X_n]]></fr:tex> be a partition of the sample space, s.t. <fr:tex
display="inline"><![CDATA[P(X_i) > 0]]></fr:tex> for all <fr:tex
display="inline"><![CDATA[i]]></fr:tex>. Then for any random variable <fr:tex
display="inline"><![CDATA[Y]]></fr:tex> on this sample space:

  <fr:tex
display="block"><![CDATA[     E(Y) = \sum _{i=1}^n E(Y \mid  X_i)P(X_i)   ]]></fr:tex></fr:p></fr:mainmatter><fr:backmatter /></fr:tree><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>339</fr:anchor><fr:addr
type="user">ShanghaiTech-SI140A-0012</fr:addr><fr:route>ShanghaiTech-SI140A-0012.xml</fr:route><fr:title
text="Conditional Expectation Given an R.V.">Conditional Expectation Given an R.V.</fr:title><fr:taxon>Definition</fr:taxon><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>10</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>Let <fr:tex
display="inline"><![CDATA[X, Y]]></fr:tex> be two random variables. Then the <fr:strong>conditional expectation of <fr:tex
display="inline"><![CDATA[Y]]></fr:tex> given <fr:tex
display="inline"><![CDATA[X]]></fr:tex></fr:strong> is a function of <fr:tex
display="inline"><![CDATA[X]]></fr:tex>, denoted by <fr:tex
display="inline"><![CDATA[E(Y \mid  X)]]></fr:tex>, defined as:

  <fr:tex
display="block"><![CDATA[     E(Y \mid  X) = \sum _y y P(Y = y \mid  X)   ]]></fr:tex>

  <fr:tex
display="block"><![CDATA[     E(Y \mid  X) = \int _{-\infty }^{+\infty } y f_{Y \mid  X}(y \mid  x) \, \mathrm {d} y   ]]></fr:tex></fr:p></fr:mainmatter><fr:backmatter /></fr:tree><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>340</fr:anchor><fr:addr
type="user">ShanghaiTech-SI140A-0013</fr:addr><fr:route>ShanghaiTech-SI140A-0013.xml</fr:route><fr:title
text="Adam's Law">Adam's Law</fr:title><fr:taxon>Theorem</fr:taxon><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>10</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>For any random variables <fr:tex
display="inline"><![CDATA[X, Y]]></fr:tex>:

  <fr:tex
display="block"><![CDATA[     E ( E(Y \mid  X) ) = E(Y)   ]]></fr:tex></fr:p></fr:mainmatter><fr:backmatter /></fr:tree><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>341</fr:anchor><fr:addr
type="user">ShanghaiTech-SI140A-0014</fr:addr><fr:route>ShanghaiTech-SI140A-0014.xml</fr:route><fr:title
text="Conditional Variance">Conditional Variance</fr:title><fr:taxon>Definition</fr:taxon><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>10</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>The <fr:strong>conditional variance</fr:strong> of a r.v. <fr:tex
display="inline"><![CDATA[Y]]></fr:tex> given <fr:tex
display="inline"><![CDATA[X]]></fr:tex> is defined as

  <fr:tex
display="block"><![CDATA[     \operatorname {Var} (Y \mid  X) = E \left ( (Y - E(Y \mid  X))^2 \mid  X \right )   ]]></fr:tex>

  this is equivalent to:

  <fr:tex
display="block"><![CDATA[     \operatorname {Var} (Y \mid  X) = E(Y^2 \mid  X) - E^2(Y \mid  X)   ]]></fr:tex></fr:p></fr:mainmatter><fr:backmatter /></fr:tree><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>342</fr:anchor><fr:addr
type="user">ShanghaiTech-SI140A-0015</fr:addr><fr:route>ShanghaiTech-SI140A-0015.xml</fr:route><fr:title
text="Eve's Law">Eve's Law</fr:title><fr:taxon>Theorem</fr:taxon><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>10</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>For any two r.v. <fr:tex
display="inline"><![CDATA[X]]></fr:tex> and <fr:tex
display="inline"><![CDATA[Y]]></fr:tex>, we have

  <fr:tex
display="block"><![CDATA[     \operatorname {Var}(Y) = E(\operatorname {Var}(Y \mid  X)) + \operatorname {Var}(E(Y \mid  X))   ]]></fr:tex></fr:p></fr:mainmatter><fr:backmatter /></fr:tree><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>343</fr:anchor><fr:addr
type="user">ShanghaiTech-SI140A-0016</fr:addr><fr:route>ShanghaiTech-SI140A-0016.xml</fr:route><fr:title
text="Estimation (Basic Problem)">Estimation (Basic Problem)</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>10</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>Given a random variable <fr:tex
display="inline"><![CDATA[X]]></fr:tex> and a sample <fr:tex
display="inline"><![CDATA[ X_1, X_2, \dots , X_n]]></fr:tex> we want to estimate the distribution of <fr:tex
display="inline"><![CDATA[X]]></fr:tex>.</fr:p><fr:p>The <fr:strong>Estimator</fr:strong> is a function <fr:tex
display="inline"><![CDATA[\hat {X} = g(X_1, X_2, \dots , X_n)]]></fr:tex>. The <fr:strong>cost function</fr:strong> is a function <fr:tex
display="inline"><![CDATA[c(X, \hat {X})]]></fr:tex> that measures the quality of the estimator. We want to minimize the expected cost <fr:tex
display="inline"><![CDATA[E(c(X, \hat {X}))]]></fr:tex>.</fr:p><fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>344</fr:anchor><fr:addr
type="user">ShanghaiTech-SI140A-0017</fr:addr><fr:route>ShanghaiTech-SI140A-0017.xml</fr:route><fr:title
text="Least Square Estimation">Least Square Estimation</fr:title><fr:taxon>Definition</fr:taxon><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>10</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>Given a random variable <fr:tex
display="inline"><![CDATA[X]]></fr:tex> and a sample <fr:tex
display="inline"><![CDATA[ X_1, X_2, \dots , X_n]]></fr:tex>, let the cost function be the square of the difference between <fr:tex
display="inline"><![CDATA[X]]></fr:tex> and <fr:tex
display="inline"><![CDATA[\hat {X}]]></fr:tex>:

  <fr:tex
display="block"><![CDATA[     c(X, \hat {X}) = |X - \hat {X}|^2   ]]></fr:tex>

  The best guess is called the <fr:strong>Least Square Estimator</fr:strong>:</fr:p></fr:mainmatter><fr:backmatter /></fr:tree><fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>345</fr:anchor><fr:addr
type="user">ShanghaiTech-SI140A-0018</fr:addr><fr:route>ShanghaiTech-SI140A-0018.xml</fr:route><fr:title
text="Linear Least Square Estimation">Linear Least Square Estimation</fr:title><fr:taxon>Definition</fr:taxon><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>10</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>If the estimator in a LSE estimation is <fr:strong>linear</fr:strong>, then it is called a <fr:strong>Linear Least Square Estimator (LLSE)</fr:strong>.</fr:p><fr:p>The LLSE of <fr:tex
display="inline"><![CDATA[Y]]></fr:tex> given <fr:tex
display="inline"><![CDATA[X]]></fr:tex>, denoted by <fr:tex
display="inline"><![CDATA[L [Y \mid  X] ]]></fr:tex> is the linear function <fr:tex
display="inline"><![CDATA[a + b X]]></fr:tex> that minimizes the mean square error <fr:tex
display="inline"><![CDATA[E[(Y - a - b X)^2]]]></fr:tex>.

  <fr:tex
display="block"><![CDATA[     L [Y \mid  X] = E[Y] + \frac {\operatorname {Cov}(X, Y)}{\operatorname {Var}(X)} (X - E[X])   ]]></fr:tex></fr:p></fr:mainmatter><fr:backmatter /></fr:tree><fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>346</fr:anchor><fr:addr
type="user">ShanghaiTech-SI140A-0019</fr:addr><fr:route>ShanghaiTech-SI140A-0019.xml</fr:route><fr:title
text="Minimum Mean Square Estimation">Minimum Mean Square Estimation</fr:title><fr:taxon>Definition</fr:taxon><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>10</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>If the estimator is an arbitrary function, and the cost function is the mean square error, then the estimator is called a <fr:strong>Minimum Mean Square Estimator (MMSE)</fr:strong>.</fr:p><fr:p>The MMSE of <fr:tex
display="inline"><![CDATA[Y]]></fr:tex> given <fr:tex
display="inline"><![CDATA[X]]></fr:tex> is given by the conditional expectation:

  <fr:tex
display="block"><![CDATA[     E[Y \mid  X]   ]]></fr:tex></fr:p></fr:mainmatter><fr:backmatter /></fr:tree></fr:mainmatter><fr:backmatter /></fr:tree></fr:mainmatter><fr:backmatter /></fr:tree></fr:mainmatter><fr:backmatter /></fr:tree></fr:backmatter></fr:tree>